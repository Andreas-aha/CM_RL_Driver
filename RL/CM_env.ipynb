{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "#import reverb\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logzero\n",
    "from logzero import logger as logging\n",
    "\n",
    "from tf_agents.environments import py_environment, batched_py_environment, tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.sac import sac_agent\n",
    "from tf_agents.agents.sac import tanh_normal_projection_network\n",
    "from tf_agents.experimental.train import actor\n",
    "from tf_agents.experimental.train import learner\n",
    "from tf_agents.experimental.train import triggers\n",
    "from tf_agents.experimental.train.utils import spec_utils\n",
    "from tf_agents.experimental.train.utils import strategy_utils\n",
    "from tf_agents.experimental.train.utils import train_utils\n",
    "from tf_agents.metrics import py_metrics, tf_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import py_tf_eager_policy, py_tf_policy\n",
    "from tf_agents.policies import random_py_policy, random_tf_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.eval import metric_utils\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "from tf_agents.drivers import dynamic_step_driver, dynamic_episode_driver\n",
    "\n",
    "\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from CM_py_env import CarMakerEnv\n",
    "from server import Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#root_dir = \"%s/rl_data/run%s\" % (os.getcwd(),  timestr)\n",
    "#os.mkdir(root_dir)\n",
    "root_dir = \"/home/andreas-z97x-ud3h/CM_Projects/CM_RL_Driver/RL/rl_data/run20201224-133929\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter\n",
    "num_iterations = 4000000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 10000 # @param {type:\"integer\"}\n",
    "train_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 100000 # @param {type:\"integer\"}\n",
    "collect_actor_num_steps = 2\n",
    "collect_actor_num_episodes = None # steps or episodes must be none\n",
    "\n",
    "batch_size = 512 # @param {type:\"integer\"}\n",
    "\n",
    "critic_learning_rate = 4e-4 # @param {typ\"}ber\"}\n",
    "actor_learning_rate = 8e-4 # @param {type\"}er\"}\n",
    "alpha_learning_rate = 4e-4 # @param {type\"}er\"}\n",
    "target_update_tau = 0.005 # @param {type:\"number\"}\n",
    "target_update_period = 1 # @param {type:\"number\"}\n",
    "gamma = 0.99 # @param {type:\"number\"}\n",
    "reward_scale_factor = 15.0 # @param {type:\"number\"}\n",
    "\n",
    "actor_fc_layer_params = (256, 256)\n",
    "critic_joint_fc_layer_params = (256, 256)\n",
    "\n",
    "log_interval = 100 # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 3 # @param {type:\"integer\"}\n",
    "eval_interval = 10000000000000000000 # @param {type:\"integer\"}\n",
    "\n",
    "policy_save_interval = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "summary_interval=1000\n",
    "summaries_flush_secs=10\n",
    "\n",
    "eval_metrics_callback=None\n",
    "\n",
    "train_checkpoint_interval=50000\n",
    "policy_checkpoint_interval=50000\n",
    "rb_checkpoint_interval=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logzero.logfile(\"%s/rotating-logfile.log\" % root_dir, maxBytes=1e6, backupCount=3)\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(root_dir, 'train')\n",
    "eval_dir = os.path.join(root_dir, 'eval')\n",
    "\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    train_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    eval_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "eval_metrics = [\n",
    "    tf_metrics.AverageReturnMetric(buffer_size=num_eval_episodes),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(buffer_size=num_eval_episodes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One Environment for collecting data during eval, and one for eval\n",
    "#Collect langsamer\n",
    "\n",
    "collect_env = CarMakerEnv(RTFac=999999, mode='collect', gamma=gamma, server=0)\n",
    "#collect_env2 = CarMakerEnv(RTFac=2, mode='collect', gamma=gamma, server=1)\n",
    "#collect_env3 = CarMakerEnv(RTFac=1, mode='collect', gamma=gamma, server=2)\n",
    "#collect_env4 = CarMakerEnv(RTFac=1, mode='collect', gamma=gamma, server=3)\n",
    "\n",
    "#collect_env = batched_py_environment.BatchedPyEnvironment( [collect_env1, collect_env2] )\n",
    "#eval_env = CarMakerEnv(RTFac=999999, mode='evaluate', gamma=gamma, server=1)\n",
    "\n",
    "#eval_env = collect_env\n",
    "\n",
    "tf_collect_env = tf_py_environment.TFPyEnvironment(collect_env)\n",
    "tf_eval_env = tf_collect_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Observation Spec:\nTensorSpec(shape=(23,), dtype=tf.float32, name='observation')\nAction Spec:\nBoundedTensorSpec(shape=(2,), dtype=tf.float32, name='action', minimum=array([-1.   , -4.999], dtype=float32), maximum=array([1.   , 4.999], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Check specs\n",
    "\n",
    "print('Observation Spec:')\n",
    "print(tf_collect_env.time_step_spec().observation)\n",
    "print('Action Spec:')\n",
    "print(tf_collect_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "# All variables and Agents need to be created under strategy.scope(), as you'll see below.\n",
    "\n",
    "# Critic for estimate of action values\n",
    "# Input is observation and an action\n",
    "# Output is estimate of action value (to see how good it would be)\n",
    "\n",
    "observation_spec, action_spec, time_step_spec = (\n",
    "      spec_utils.get_tensor_specs(tf_collect_env))\n",
    "\n",
    "\n",
    "critic_net = critic_network.CriticNetwork(\n",
    "      (observation_spec, action_spec),\n",
    "      observation_fc_layer_params=None,\n",
    "      action_fc_layer_params=None,\n",
    "      joint_fc_layer_params=critic_joint_fc_layer_params,\n",
    "      kernel_initializer='glorot_uniform',\n",
    "      last_kernel_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor network predicts parameters for a tanh-squashed MultivariateNormalDiag distribution.\n",
    "# Will be sampled conditioned on the current state (observation), if generation of action is needed.\n",
    "\n",
    "\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    observation_spec,\n",
    "    action_spec,\n",
    "    fc_layer_params=actor_fc_layer_params,\n",
    "    continuous_projection_net=(\n",
    "        tanh_normal_projection_network.TanhNormalProjectionNetwork))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init agent\n",
    "5\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "tf_agent = sac_agent.SacAgent(\n",
    "    time_step_spec,\n",
    "    action_spec,\n",
    "    actor_network=actor_net,\n",
    "    critic_network=critic_net,\n",
    "    actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=actor_learning_rate),\n",
    "    critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=critic_learning_rate),\n",
    "    alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=alpha_learning_rate),\n",
    "    target_update_tau=target_update_tau,\n",
    "    target_update_period=target_update_period,\n",
    "    td_errors_loss_fn=tf.math.squared_difference,\n",
    "    gamma=gamma,\n",
    "    reward_scale_factor=reward_scale_factor,\n",
    "    train_step_counter=global_step)\n",
    "\n",
    "tf_agent.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    tf_agent.collect_data_spec,\n",
    "    batch_size=1,\n",
    "    max_length=replay_buffer_capacity)\n",
    "# 6 instead of 2 for TD(5)\n",
    "\n",
    "def _filter_invalid_transition(trajectories, unused_arg1):\n",
    "      return ~trajectories.is_boundary()[0]\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=batch_size, num_steps=2, num_parallel_calls=2).unbatch().filter(\n",
    "            _filter_invalid_transition).batch(batch_size).prefetch(100)\n",
    "\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Policies\n",
    "# Agent has 2 policies\n",
    "\n",
    "# agent.policy — The main policy that is used for evaluation and deployment.\n",
    "# agent.collect_policy — A second policy that is used for data collection.\n",
    "\n",
    "tf_eval_policy = greedy_policy.GreedyPolicy(tf_agent.policy)\n",
    "\n",
    "tf_collect_policy = tf_agent.collect_policy\n",
    "\n",
    "# Additional random policy for initial collector\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(\n",
    "  tf_collect_env.time_step_spec(), tf_collect_env.action_spec())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(\n",
    "        buffer_size=num_eval_episodes, batch_size=tf_collect_env.batch_size),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(\n",
    "        buffer_size=num_eval_episodes, batch_size=tf_collect_env.batch_size),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f79f0c0cc40>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=train_dir,\n",
    "    agent=tf_agent,\n",
    "    global_step=global_step,\n",
    "    metrics=metric_utils.MetricsGroup(train_metrics, 'train_metrics'))\n",
    "policy_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(train_dir, 'policy'),\n",
    "    policy=tf_eval_policy,\n",
    "    global_step=global_step)\n",
    "rb_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(train_dir, 'replay_buffer'),\n",
    "    max_to_keep=1,\n",
    "    replay_buffer=replay_buffer)\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "rb_checkpointer.initialize_or_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor with the random policy and collect experiences to seed the replay buffer with\n",
    "\n",
    "initial_collect_actor = dynamic_step_driver.DynamicStepDriver(\n",
    "  tf_eval_env,\n",
    "  random_policy,\n",
    "  num_steps=1,\n",
    "  observers=replay_observer+train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an Actor with the collect policy to gather more experiences during training\n",
    "\n",
    "# Steps per run nun 5 statt 1, weil smoother?\n",
    "\n",
    "\n",
    "if collect_actor_num_episodes is not None and collect_actor_num_steps is not None:\n",
    "  raise ValueError(\"Define num episodes OR num steps. One of them must be None.\")\n",
    "elif collect_actor_num_episodes is None:\n",
    "  collect_actor = dynamic_step_driver.DynamicStepDriver(\n",
    "    tf_collect_env,\n",
    "    tf_collect_policy,\n",
    "    num_steps=collect_actor_num_steps,\n",
    "    observers=replay_observer+train_metrics)\n",
    "elif collect_actor_num_steps is None:\n",
    "  collect_actor = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    tf_collect_env,\n",
    "    tf_collect_policy,\n",
    "    num_episodes=collect_actor_num_episodes,\n",
    "    observers=replay_observer+train_metrics)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_actor.run = common.function(initial_collect_actor.run)\n",
    "collect_actor.run = common.function(collect_actor.run)\n",
    "tf_agent.train = common.function(tf_agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = None\n",
    "policy_state = tf_collect_policy.get_initial_state(tf_collect_env.batch_size)\n",
    "timed_at_step = global_step.numpy()\n",
    "time_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_val = train_metrics[0].result()\n",
    "Server(14100).send_gui(\"DVAWrite RL_Agent.Episodes %d\" % episode_val)\n",
    "global_step_val = global_step.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if replay_buffer.num_frames() == 0:\n",
    "    # Collect initial replay data.\n",
    "    for _ in tqdm(range(initial_collect_steps)):\n",
    "        initial_collect_actor.run()\n",
    "        if episode_val != train_metrics[0].result().numpy():\n",
    "            episode_val = train_metrics[0].result().numpy()\n",
    "            Server(14100).send_gui(\"DVAWrite RL_Agent.Episodes %d\" % episode_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    experience, _ = next(iterator)\n",
    "    return tf_agent.train(experience)\n",
    "\n",
    "train_step = common.function(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0, loss = 849734.125000\n",
      "[I 201225 15:37:04 <ipython-input-23-1e78b71a1ddb>:19] 12.059 steps/sec\n",
      "[I 201225 15:37:12 <ipython-input-23-1e78b71a1ddb>:17] step = 1069400, loss = 1420282.375000\n",
      "[I 201225 15:37:12 <ipython-input-23-1e78b71a1ddb>:19] 12.309 steps/sec\n",
      "[I 201225 15:37:21 <ipython-input-23-1e78b71a1ddb>:17] step = 1069500, loss = 1895660.500000\n",
      "[I 201225 15:37:21 <ipython-input-23-1e78b71a1ddb>:19] 12.565 steps/sec\n",
      "[I 201225 15:37:29 <ipython-input-23-1e78b71a1ddb>:17] step = 1069600, loss = 1279064.750000\n",
      "[I 201225 15:37:29 <ipython-input-23-1e78b71a1ddb>:19] 12.306 steps/sec\n",
      "[I 201225 15:37:38 <ipython-input-23-1e78b71a1ddb>:17] step = 1069700, loss = 2130631.750000\n",
      "[I 201225 15:37:38 <ipython-input-23-1e78b71a1ddb>:19] 12.575 steps/sec\n",
      "[I 201225 15:37:46 <ipython-input-23-1e78b71a1ddb>:17] step = 1069800, loss = 836886.625000\n",
      "[I 201225 15:37:46 <ipython-input-23-1e78b71a1ddb>:19] 12.312 steps/sec\n",
      "[I 201225 15:37:55 <ipython-input-23-1e78b71a1ddb>:17] step = 1069900, loss = 771078.750000\n",
      "[I 201225 15:37:55 <ipython-input-23-1e78b71a1ddb>:19] 12.404 steps/sec\n",
      "[I 201225 15:38:03 <ipython-input-23-1e78b71a1ddb>:17] step = 1070000, loss = 868758.312500\n",
      "[I 201225 15:38:03 <ipython-input-23-1e78b71a1ddb>:19] 12.435 steps/sec\n",
      "[I 201225 15:38:12 <ipython-input-23-1e78b71a1ddb>:17] step = 1070100, loss = 1630024.625000\n",
      "[I 201225 15:38:12 <ipython-input-23-1e78b71a1ddb>:19] 12.290 steps/sec\n",
      "[I 201225 15:38:21 <ipython-input-23-1e78b71a1ddb>:17] step = 1070200, loss = 1586656.250000\n",
      "[I 201225 15:38:21 <ipython-input-23-1e78b71a1ddb>:19] 12.346 steps/sec\n",
      "[I 201225 15:38:29 <ipython-input-23-1e78b71a1ddb>:17] step = 1070300, loss = 1618050.750000\n",
      "[I 201225 15:38:29 <ipython-input-23-1e78b71a1ddb>:19] 12.718 steps/sec\n",
      "[I 201225 15:38:38 <ipython-input-23-1e78b71a1ddb>:17] step = 1070400, loss = 1047984.687500\n",
      "[I 201225 15:38:38 <ipython-input-23-1e78b71a1ddb>:19] 12.017 steps/sec\n",
      "[I 201225 15:38:46 <ipython-input-23-1e78b71a1ddb>:17] step = 1070500, loss = 3478411.000000\n",
      "[I 201225 15:38:46 <ipython-input-23-1e78b71a1ddb>:19] 12.475 steps/sec\n",
      "[I 201225 15:38:55 <ipython-input-23-1e78b71a1ddb>:17] step = 1070600, loss = 3323758.000000\n",
      "[I 201225 15:38:55 <ipython-input-23-1e78b71a1ddb>:19] 12.068 steps/sec\n",
      "[I 201225 15:39:03 <ipython-input-23-1e78b71a1ddb>:17] step = 1070700, loss = 1720789.500000\n",
      "[I 201225 15:39:03 <ipython-input-23-1e78b71a1ddb>:19] 12.673 steps/sec\n",
      "[I 201225 15:39:12 <ipython-input-23-1e78b71a1ddb>:17] step = 1070800, loss = 2755889.250000\n",
      "[I 201225 15:39:12 <ipython-input-23-1e78b71a1ddb>:19] 12.540 steps/sec\n",
      "[I 201225 15:39:20 <ipython-input-23-1e78b71a1ddb>:17] step = 1070900, loss = 1622478.250000\n",
      "[I 201225 15:39:20 <ipython-input-23-1e78b71a1ddb>:19] 12.793 steps/sec\n",
      "[I 201225 15:39:29 <ipython-input-23-1e78b71a1ddb>:17] step = 1071000, loss = 4500759.000000\n",
      "[I 201225 15:39:29 <ipython-input-23-1e78b71a1ddb>:19] 12.496 steps/sec\n",
      "[I 201225 15:39:37 <ipython-input-23-1e78b71a1ddb>:17] step = 1071100, loss = 1005112.062500\n",
      "[I 201225 15:39:37 <ipython-input-23-1e78b71a1ddb>:19] 12.860 steps/sec\n",
      "[I 201225 15:39:45 <ipython-input-23-1e78b71a1ddb>:17] step = 1071200, loss = 3362214.500000\n",
      "[I 201225 15:39:45 <ipython-input-23-1e78b71a1ddb>:19] 12.848 steps/sec\n",
      "[I 201225 15:39:54 <ipython-input-23-1e78b71a1ddb>:17] step = 1071300, loss = 1355510.250000\n",
      "[I 201225 15:39:54 <ipython-input-23-1e78b71a1ddb>:19] 12.255 steps/sec\n",
      "[I 201225 15:40:02 <ipython-input-23-1e78b71a1ddb>:17] step = 1071400, loss = 1121958.500000\n",
      "[I 201225 15:40:02 <ipython-input-23-1e78b71a1ddb>:19] 12.134 steps/sec\n",
      "[I 201225 15:40:11 <ipython-input-23-1e78b71a1ddb>:17] step = 1071500, loss = 4192888.750000\n",
      "[I 201225 15:40:11 <ipython-input-23-1e78b71a1ddb>:19] 12.813 steps/sec\n",
      "[I 201225 15:40:19 <ipython-input-23-1e78b71a1ddb>:17] step = 1071600, loss = 1757716.000000\n",
      "[I 201225 15:40:19 <ipython-input-23-1e78b71a1ddb>:19] 12.380 steps/sec\n",
      "[I 201225 15:40:28 <ipython-input-23-1e78b71a1ddb>:17] step = 1071700, loss = 2907972.000000\n",
      "[I 201225 15:40:28 <ipython-input-23-1e78b71a1ddb>:19] 12.154 steps/sec\n",
      "[I 201225 15:40:37 <ipython-input-23-1e78b71a1ddb>:17] step = 1071800, loss = 2653569.750000\n",
      "[I 201225 15:40:37 <ipython-input-23-1e78b71a1ddb>:19] 12.153 steps/sec\n",
      "[I 201225 15:40:45 <ipython-input-23-1e78b71a1ddb>:17] step = 1071900, loss = 1529466.625000\n",
      "[I 201225 15:40:45 <ipython-input-23-1e78b71a1ddb>:19] 12.535 steps/sec\n",
      "[I 201225 15:40:54 <ipython-input-23-1e78b71a1ddb>:17] step = 1072000, loss = 4822278.000000\n",
      "[I 201225 15:40:54 <ipython-input-23-1e78b71a1ddb>:19] 11.510 steps/sec\n",
      "[I 201225 15:41:03 <ipython-input-23-1e78b71a1ddb>:17] step = 1072100, loss = 5560282.000000\n",
      "[I 201225 15:41:03 <ipython-input-23-1e78b71a1ddb>:19] 12.028 steps/sec\n",
      "[I 201225 15:41:12 <ipython-input-23-1e78b71a1ddb>:17] step = 1072200, loss = 1281075.375000\n",
      "[I 201225 15:41:12 <ipython-input-23-1e78b71a1ddb>:19] 12.032 steps/sec\n",
      "[I 201225 15:41:21 <ipython-input-23-1e78b71a1ddb>:17] step = 1072300, loss = 7607378944.000000\n",
      "[I 201225 15:41:21 <ipython-input-23-1e78b71a1ddb>:19] 11.780 steps/sec\n",
      "[I 201225 15:41:29 <ipython-input-23-1e78b71a1ddb>:17] step = 1072400, loss = 5631211.000000\n",
      "[I 201225 15:41:29 <ipython-input-23-1e78b71a1ddb>:19] 12.297 steps/sec\n",
      "[I 201225 15:41:38 <ipython-input-23-1e78b71a1ddb>:17] step = 1072500, loss = 4915775.500000\n",
      "[I 201225 15:41:38 <ipython-input-23-1e78b71a1ddb>:19] 12.833 steps/sec\n",
      "[I 201225 15:41:46 <ipython-input-23-1e78b71a1ddb>:17] step = 1072600, loss = 3815614.500000\n",
      "[I 201225 15:41:46 <ipython-input-23-1e78b71a1ddb>:19] 12.350 steps/sec\n",
      "[I 201225 15:41:55 <ipython-input-23-1e78b71a1ddb>:17] step = 1072700, loss = 868688.187500\n",
      "[I 201225 15:41:55 <ipython-input-23-1e78b71a1ddb>:19] 12.070 steps/sec\n",
      "[I 201225 15:42:04 <ipython-input-23-1e78b71a1ddb>:17] step = 1072800, loss = 1271618.000000\n",
      "[I 201225 15:42:04 <ipython-input-23-1e78b71a1ddb>:19] 12.273 steps/sec\n",
      "[I 201225 15:42:12 <ipython-input-23-1e78b71a1ddb>:17] step = 1072900, loss = 1437302.875000\n",
      "[I 201225 15:42:12 <ipython-input-23-1e78b71a1ddb>:19] 12.265 steps/sec\n",
      "[I 201225 15:42:21 <ipython-input-23-1e78b71a1ddb>:17] step = 1073000, loss = 954488.250000\n",
      "[I 201225 15:42:21 <ipython-input-23-1e78b71a1ddb>:19] 12.386 steps/sec\n",
      "[I 201225 15:42:29 <ipython-input-23-1e78b71a1ddb>:17] step = 1073100, loss = 11356384.000000\n",
      "[I 201225 15:42:29 <ipython-input-23-1e78b71a1ddb>:19] 12.804 steps/sec\n",
      "[I 201225 15:42:38 <ipython-input-23-1e78b71a1ddb>:17] step = 1073200, loss = 1631017.500000\n",
      "[I 201225 15:42:38 <ipython-input-23-1e78b71a1ddb>:19] 11.801 steps/sec\n",
      "[I 201225 15:42:47 <ipython-input-23-1e78b71a1ddb>:17] step = 1073300, loss = 1789833.125000\n",
      "[I 201225 15:42:47 <ipython-input-23-1e78b71a1ddb>:19] 11.756 steps/sec\n",
      "[I 201225 15:42:56 <ipython-input-23-1e78b71a1ddb>:17] step = 1073400, loss = 3262922.000000\n",
      "[I 201225 15:42:56 <ipython-input-23-1e78b71a1ddb>:19] 11.954 steps/sec\n",
      "[I 201225 15:43:04 <ipython-input-23-1e78b71a1ddb>:17] step = 1073500, loss = 5210755.500000\n",
      "[I 201225 15:43:04 <ipython-input-23-1e78b71a1ddb>:19] 12.305 steps/sec\n",
      "[I 201225 15:43:13 <ipython-input-23-1e78b71a1ddb>:17] step = 1073600, loss = 1252027.500000\n",
      "[I 201225 15:43:13 <ipython-input-23-1e78b71a1ddb>:19] 12.015 steps/sec\n",
      "[I 201225 15:43:21 <ipython-input-23-1e78b71a1ddb>:17] step = 1073700, loss = 2723155.000000\n",
      "[I 201225 15:43:21 <ipython-input-23-1e78b71a1ddb>:19] 12.507 steps/sec\n",
      "[I 201225 15:43:30 <ipython-input-23-1e78b71a1ddb>:17] step = 1073800, loss = 725259.250000\n",
      "[I 201225 15:43:30 <ipython-input-23-1e78b71a1ddb>:19] 12.027 steps/sec\n",
      "[I 201225 15:43:39 <ipython-input-23-1e78b71a1ddb>:17] step = 1073900, loss = 1796190.500000\n",
      "[I 201225 15:43:39 <ipython-input-23-1e78b71a1ddb>:19] 12.506 steps/sec\n",
      "[I 201225 15:43:47 <ipython-input-23-1e78b71a1ddb>:17] step = 1074000, loss = 2214172.250000\n",
      "[I 201225 15:43:47 <ipython-input-23-1e78b71a1ddb>:19] 12.347 steps/sec\n",
      "[I 201225 15:43:56 <ipython-input-23-1e78b71a1ddb>:17] step = 1074100, loss = 4017869.750000\n",
      "[I 201225 15:43:56 <ipython-input-23-1e78b71a1ddb>:19] 12.046 steps/sec\n",
      "[I 201225 15:44:05 <ipython-input-23-1e78b71a1ddb>:17] step = 1074200, loss = 526195.687500\n",
      "[I 201225 15:44:05 <ipython-input-23-1e78b71a1ddb>:19] 11.986 steps/sec\n",
      "[I 201225 15:44:13 <ipython-input-23-1e78b71a1ddb>:17] step = 1074300, loss = 744801.187500\n",
      "[I 201225 15:44:13 <ipython-input-23-1e78b71a1ddb>:19] 12.424 steps/sec\n",
      "[I 201225 15:44:22 <ipython-input-23-1e78b71a1ddb>:17] step = 1074400, loss = 754118.000000\n",
      "[I 201225 15:44:22 <ipython-input-23-1e78b71a1ddb>:19] 11.702 steps/sec\n",
      "[I 201225 15:44:31 <ipython-input-23-1e78b71a1ddb>:17] step = 1074500, loss = 551193.812500\n",
      "[I 201225 15:44:31 <ipython-input-23-1e78b71a1ddb>:19] 12.377 steps/sec\n",
      "[I 201225 15:44:39 <ipython-input-23-1e78b71a1ddb>:17] step = 1074600, loss = 681554.062500\n",
      "[I 201225 15:44:39 <ipython-input-23-1e78b71a1ddb>:19] 12.623 steps/sec\n",
      "[I 201225 15:44:48 <ipython-input-23-1e78b71a1ddb>:17] step = 1074700, loss = 1153386.375000\n",
      "[I 201225 15:44:48 <ipython-input-23-1e78b71a1ddb>:19] 12.217 steps/sec\n",
      "[I 201225 15:44:56 <ipython-input-23-1e78b71a1ddb>:17] step = 1074800, loss = 639715.375000\n",
      "[I 201225 15:44:56 <ipython-input-23-1e78b71a1ddb>:19] 12.497 steps/sec\n",
      "[I 201225 15:45:05 <ipython-input-23-1e78b71a1ddb>:17] step = 1074900, loss = 445334.812500\n",
      "[I 201225 15:45:05 <ipython-input-23-1e78b71a1ddb>:19] 12.342 steps/sec\n",
      "[I 201225 15:45:14 <ipython-input-23-1e78b71a1ddb>:17] step = 1075000, loss = 750017.187500\n",
      "[I 201225 15:45:14 <ipython-input-23-1e78b71a1ddb>:19] 12.605 steps/sec\n",
      "[I 201225 15:45:22 <ipython-input-23-1e78b71a1ddb>:17] step = 1075100, loss = 624715.625000\n",
      "[I 201225 15:45:22 <ipython-input-23-1e78b71a1ddb>:19] 12.464 steps/sec\n",
      "[I 201225 15:45:31 <ipython-input-23-1e78b71a1ddb>:17] step = 1075200, loss = 3047412.250000\n",
      "[I 201225 15:45:31 <ipython-input-23-1e78b71a1ddb>:19] 12.227 steps/sec\n",
      "[I 201225 15:45:39 <ipython-input-23-1e78b71a1ddb>:17] step = 1075300, loss = 735972.062500\n",
      "[I 201225 15:45:39 <ipython-input-23-1e78b71a1ddb>:19] 12.219 steps/sec\n",
      "[I 201225 15:45:48 <ipython-input-23-1e78b71a1ddb>:17] step = 1075400, loss = 605801.562500\n",
      "[I 201225 15:45:48 <ipython-input-23-1e78b71a1ddb>:19] 11.918 steps/sec\n",
      "[I 201225 15:45:57 <ipython-input-23-1e78b71a1ddb>:17] step = 1075500, loss = 533754.375000\n",
      "[I 201225 15:45:57 <ipython-input-23-1e78b71a1ddb>:19] 11.832 steps/sec\n",
      "[I 201225 15:46:06 <ipython-input-23-1e78b71a1ddb>:17] step = 1075600, loss = 1121452.625000\n",
      "[I 201225 15:46:06 <ipython-input-23-1e78b71a1ddb>:19] 11.812 steps/sec\n",
      "[I 201225 15:46:14 <ipython-input-23-1e78b71a1ddb>:17] step = 1075700, loss = 1654460.250000\n",
      "[I 201225 15:46:14 <ipython-input-23-1e78b71a1ddb>:19] 12.628 steps/sec\n",
      "[I 201225 15:46:23 <ipython-input-23-1e78b71a1ddb>:17] step = 1075800, loss = 537853.375000\n",
      "[I 201225 15:46:23 <ipython-input-23-1e78b71a1ddb>:19] 12.324 steps/sec\n",
      "[I 201225 15:46:32 <ipython-input-23-1e78b71a1ddb>:17] step = 1075900, loss = 619971.687500\n",
      "[I 201225 15:46:32 <ipython-input-23-1e78b71a1ddb>:19] 12.249 steps/sec\n",
      "[I 201225 15:46:40 <ipython-input-23-1e78b71a1ddb>:17] step = 1076000, loss = 653885.375000\n",
      "[I 201225 15:46:40 <ipython-input-23-1e78b71a1ddb>:19] 12.171 steps/sec\n",
      "[I 201225 15:46:49 <ipython-input-23-1e78b71a1ddb>:17] step = 1076100, loss = 650716.937500\n",
      "[I 201225 15:46:49 <ipython-input-23-1e78b71a1ddb>:19] 12.582 steps/sec\n",
      "[I 201225 15:46:57 <ipython-input-23-1e78b71a1ddb>:17] step = 1076200, loss = 621061.937500\n",
      "[I 201225 15:46:57 <ipython-input-23-1e78b71a1ddb>:19] 12.761 steps/sec\n",
      "[I 201225 15:47:06 <ipython-input-23-1e78b71a1ddb>:17] step = 1076300, loss = 617999.750000\n",
      "[I 201225 15:47:06 <ipython-input-23-1e78b71a1ddb>:19] 12.028 steps/sec\n",
      "[I 201225 15:47:14 <ipython-input-23-1e78b71a1ddb>:17] step = 1076400, loss = 591171.562500\n",
      "[I 201225 15:47:14 <ipython-input-23-1e78b71a1ddb>:19] 12.199 steps/sec\n",
      "[I 201225 15:47:23 <ipython-input-23-1e78b71a1ddb>:17] step = 1076500, loss = 644867.375000\n",
      "[I 201225 15:47:23 <ipython-input-23-1e78b71a1ddb>:19] 12.639 steps/sec\n",
      "[I 201225 15:47:31 <ipython-input-23-1e78b71a1ddb>:17] step = 1076600, loss = 2239702.250000\n",
      "[I 201225 15:47:31 <ipython-input-23-1e78b71a1ddb>:19] 12.495 steps/sec\n",
      "[I 201225 15:47:40 <ipython-input-23-1e78b71a1ddb>:17] step = 1076700, loss = 1886478.750000\n",
      "[I 201225 15:47:40 <ipython-input-23-1e78b71a1ddb>:19] 12.650 steps/sec\n",
      "[I 201225 15:47:48 <ipython-input-23-1e78b71a1ddb>:17] step = 1076800, loss = 581531.125000\n",
      "[I 201225 15:47:48 <ipython-input-23-1e78b71a1ddb>:19] 12.615 steps/sec\n",
      "[I 201225 15:47:56 <ipython-input-23-1e78b71a1ddb>:17] step = 1076900, loss = 671294.250000\n",
      "[I 201225 15:47:56 <ipython-input-23-1e78b71a1ddb>:19] 12.663 steps/sec\n",
      "[I 201225 15:48:05 <ipython-input-23-1e78b71a1ddb>:17] step = 1077000, loss = 490067.281250\n",
      "[I 201225 15:48:05 <ipython-input-23-1e78b71a1ddb>:19] 12.368 steps/sec\n",
      "[I 201225 15:48:14 <ipython-input-23-1e78b71a1ddb>:17] step = 1077100, loss = 1367953.125000\n",
      "[I 201225 15:48:14 <ipython-input-23-1e78b71a1ddb>:19] 12.299 steps/sec\n",
      "[I 201225 15:48:22 <ipython-input-23-1e78b71a1ddb>:17] step = 1077200, loss = 1113355.375000\n",
      "[I 201225 15:48:22 <ipython-input-23-1e78b71a1ddb>:19] 11.893 steps/sec\n",
      "[I 201225 15:48:31 <ipython-input-23-1e78b71a1ddb>:17] step = 1077300, loss = 640542.562500\n",
      "[I 201225 15:48:31 <ipython-input-23-1e78b71a1ddb>:19] 12.723 steps/sec\n",
      "[I 201225 15:48:39 <ipython-input-23-1e78b71a1ddb>:17] step = 1077400, loss = 2757924.750000\n",
      "[I 201225 15:48:39 <ipython-input-23-1e78b71a1ddb>:19] 12.669 steps/sec\n",
      "[I 201225 15:48:48 <ipython-input-23-1e78b71a1ddb>:17] step = 1077500, loss = 530257.500000\n",
      "[I 201225 15:48:48 <ipython-input-23-1e78b71a1ddb>:19] 12.671 steps/sec\n",
      "[I 201225 15:48:58 <ipython-input-23-1e78b71a1ddb>:17] step = 1077600, loss = 420889.312500\n",
      "[I 201225 15:48:58 <ipython-input-23-1e78b71a1ddb>:19] 9.833 steps/sec\n",
      "[I 201225 15:49:06 <ipython-input-23-1e78b71a1ddb>:17] step = 1077700, loss = 436617.312500\n",
      "[I 201225 15:49:06 <ipython-input-23-1e78b71a1ddb>:19] 13.774 steps/sec\n",
      "[I 201225 15:49:14 <ipython-input-23-1e78b71a1ddb>:17] step = 1077800, loss = 483091.843750\n",
      "[I 201225 15:49:14 <ipython-input-23-1e78b71a1ddb>:19] 13.079 steps/sec\n",
      "[I 201225 15:49:22 <ipython-input-23-1e78b71a1ddb>:17] step = 1077900, loss = 731249.500000\n",
      "[I 201225 15:49:22 <ipython-input-23-1e78b71a1ddb>:19] 13.981 steps/sec\n",
      "[I 201225 15:49:29 <ipython-input-23-1e78b71a1ddb>:17] step = 1078000, loss = 668267.625000\n",
      "[I 201225 15:49:29 <ipython-input-23-1e78b71a1ddb>:19] 14.000 steps/sec\n",
      "[I 201225 15:49:37 <ipython-input-23-1e78b71a1ddb>:17] step = 1078100, loss = 350220.062500\n",
      "[I 201225 15:49:37 <ipython-input-23-1e78b71a1ddb>:19] 13.971 steps/sec\n",
      "[I 201225 15:49:45 <ipython-input-23-1e78b71a1ddb>:17] step = 1078200, loss = 474908.250000\n",
      "[I 201225 15:49:45 <ipython-input-23-1e78b71a1ddb>:19] 13.342 steps/sec\n",
      "[I 201225 15:49:52 <ipython-input-23-1e78b71a1ddb>:17] step = 1078300, loss = 478849.531250\n",
      "[I 201225 15:49:52 <ipython-input-23-1e78b71a1ddb>:19] 13.993 steps/sec\n",
      "[I 201225 15:50:00 <ipython-input-23-1e78b71a1ddb>:17] step = 1078400, loss = 456717.562500\n",
      "[I 201225 15:50:00 <ipython-input-23-1e78b71a1ddb>:19] 13.988 steps/sec\n",
      "[I 201225 15:50:07 <ipython-input-23-1e78b71a1ddb>:17] step = 1078500, loss = 482074.250000\n",
      "[I 201225 15:50:07 <ipython-input-23-1e78b71a1ddb>:19] 13.975 steps/sec\n",
      "[I 201225 15:50:15 <ipython-input-23-1e78b71a1ddb>:17] step = 1078600, loss = 826132.687500\n",
      "[I 201225 15:50:15 <ipython-input-23-1e78b71a1ddb>:19] 13.977 steps/sec\n",
      "[I 201225 15:50:23 <ipython-input-23-1e78b71a1ddb>:17] step = 1078700, loss = 530574.000000\n",
      "[I 201225 15:50:23 <ipython-input-23-1e78b71a1ddb>:19] 13.997 steps/sec\n",
      "[I 201225 15:50:30 <ipython-input-23-1e78b71a1ddb>:17] step = 1078800, loss = 3898130.500000\n",
      "[I 201225 15:50:30 <ipython-input-23-1e78b71a1ddb>:19] 13.551 steps/sec\n",
      "[I 201225 15:50:38 <ipython-input-23-1e78b71a1ddb>:17] step = 1078900, loss = 485461.062500\n",
      "[I 201225 15:50:38 <ipython-input-23-1e78b71a1ddb>:19] 14.040 steps/sec\n",
      "[I 201225 15:50:45 <ipython-input-23-1e78b71a1ddb>:17] step = 1079000, loss = 508591.250000\n",
      "[I 201225 15:50:45 <ipython-input-23-1e78b71a1ddb>:19] 14.025 steps/sec\n",
      "[I 201225 15:50:53 <ipython-input-23-1e78b71a1ddb>:17] step = 1079100, loss = 405825.906250\n",
      "[I 201225 15:50:53 <ipython-input-23-1e78b71a1ddb>:19] 14.007 steps/sec\n",
      "[I 201225 15:51:01 <ipython-input-23-1e78b71a1ddb>:17] step = 1079200, loss = 3388837.500000\n",
      "[I 201225 15:51:01 <ipython-input-23-1e78b71a1ddb>:19] 13.991 steps/sec\n",
      "[I 201225 15:51:09 <ipython-input-23-1e78b71a1ddb>:17] step = 1079300, loss = 336418.531250\n",
      "[I 201225 15:51:09 <ipython-input-23-1e78b71a1ddb>:19] 13.367 steps/sec\n",
      "[I 201225 15:51:16 <ipython-input-23-1e78b71a1ddb>:17] step = 1079400, loss = 401532.156250\n",
      "[I 201225 15:51:16 <ipython-input-23-1e78b71a1ddb>:19] 13.993 steps/sec\n",
      "[I 201225 15:51:24 <ipython-input-23-1e78b71a1ddb>:17] step = 1079500, loss = 451160.968750\n",
      "[I 201225 15:51:24 <ipython-input-23-1e78b71a1ddb>:19] 13.971 steps/sec\n",
      "[I 201225 15:51:31 <ipython-input-23-1e78b71a1ddb>:17] step = 1079600, loss = 603499.062500\n",
      "[I 201225 15:51:31 <ipython-input-23-1e78b71a1ddb>:19] 14.056 steps/sec\n",
      "[I 201225 15:51:39 <ipython-input-23-1e78b71a1ddb>:17] step = 1079700, loss = 619962.125000\n",
      "[I 201225 15:51:39 <ipython-input-23-1e78b71a1ddb>:19] 14.157 steps/sec\n",
      "[I 201225 15:51:46 <ipython-input-23-1e78b71a1ddb>:17] step = 1079800, loss = 2421006.000000\n",
      "[I 201225 15:51:46 <ipython-input-23-1e78b71a1ddb>:19] 14.105 steps/sec\n",
      "[I 201225 15:51:54 <ipython-input-23-1e78b71a1ddb>:17] step = 1079900, loss = 473078.781250\n",
      "[I 201225 15:51:54 <ipython-input-23-1e78b71a1ddb>:19] 13.206 steps/sec\n",
      "[I 201225 15:52:02 <ipython-input-23-1e78b71a1ddb>:17] step = 1080000, loss = 562690.250000\n",
      "[I 201225 15:52:02 <ipython-input-23-1e78b71a1ddb>:19] 14.114 steps/sec\n",
      "[I 201225 15:52:10 <ipython-input-23-1e78b71a1ddb>:17] step = 1080100, loss = 595245.500000\n",
      "[I 201225 15:52:10 <ipython-input-23-1e78b71a1ddb>:19] 13.415 steps/sec\n",
      "[I 201225 15:52:18 <ipython-input-23-1e78b71a1ddb>:17] step = 1080200, loss = 485139.625000\n",
      "[I 201225 15:52:18 <ipython-input-23-1e78b71a1ddb>:19] 13.002 steps/sec\n",
      "[I 201225 15:52:26 <ipython-input-23-1e78b71a1ddb>:17] step = 1080300, loss = 559833.062500\n",
      "[I 201225 15:52:26 <ipython-input-23-1e78b71a1ddb>:19] 13.606 steps/sec\n",
      "[I 201225 15:52:34 <ipython-input-23-1e78b71a1ddb>:17] step = 1080400, loss = 411511.156250\n",
      "[I 201225 15:52:34 <ipython-input-23-1e78b71a1ddb>:19] 14.125 steps/sec\n",
      "[I 201225 15:52:41 <ipython-input-23-1e78b71a1ddb>:17] step = 1080500, loss = 970613.062500\n",
      "[I 201225 15:52:41 <ipython-input-23-1e78b71a1ddb>:19] 13.614 steps/sec\n",
      "[I 201225 15:52:49 <ipython-input-23-1e78b71a1ddb>:17] step = 1080600, loss = 350825.437500\n",
      "[I 201225 15:52:49 <ipython-input-23-1e78b71a1ddb>:19] 13.480 steps/sec\n",
      "[I 201225 15:52:57 <ipython-input-23-1e78b71a1ddb>:17] step = 1080700, loss = 3329604.500000\n",
      "[I 201225 15:52:57 <ipython-input-23-1e78b71a1ddb>:19] 14.169 steps/sec\n",
      "[I 201225 15:53:05 <ipython-input-23-1e78b71a1ddb>:17] step = 1080800, loss = 1466696.000000\n",
      "[I 201225 15:53:05 <ipython-input-23-1e78b71a1ddb>:19] 14.095 steps/sec\n",
      "[I 201225 15:53:12 <ipython-input-23-1e78b71a1ddb>:17] step = 1080900, loss = 703358.687500\n",
      "[I 201225 15:53:12 <ipython-input-23-1e78b71a1ddb>:19] 14.129 steps/sec\n",
      "[I 201225 15:53:20 <ipython-input-23-1e78b71a1ddb>:17] step = 1081000, loss = 311773.750000\n",
      "[I 201225 15:53:20 <ipython-input-23-1e78b71a1ddb>:19] 14.171 steps/sec\n",
      "[I 201225 15:53:27 <ipython-input-23-1e78b71a1ddb>:17] step = 1081100, loss = 1301084.625000\n",
      "[I 201225 15:53:27 <ipython-input-23-1e78b71a1ddb>:19] 14.133 steps/sec\n",
      "[I 201225 15:53:36 <ipython-input-23-1e78b71a1ddb>:17] step = 1081200, loss = 549678.687500\n",
      "[I 201225 15:53:36 <ipython-input-23-1e78b71a1ddb>:19] 12.877 steps/sec\n",
      "[I 201225 15:53:43 <ipython-input-23-1e78b71a1ddb>:17] step = 1081300, loss = 361821.000000\n",
      "[I 201225 15:53:43 <ipython-input-23-1e78b71a1ddb>:19] 14.133 steps/sec\n",
      "[I 201225 15:53:51 <ipython-input-23-1e78b71a1ddb>:17] step = 1081400, loss = 493795.843750\n",
      "[I 201225 15:53:51 <ipython-input-23-1e78b71a1ddb>:19] 13.592 steps/sec\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": " AttributeError: 'Server' object has no attribute 'old_msg_roh'\nTraceback (most recent call last):\n\n  File \"/home/andreas-z97x-ud3h/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/home/andreas-z97x-ud3h/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py\", line 318, in _isolated_step_py\n    return self._execute(_step_py, *flattened_actions)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py\", line 214, in _execute\n    return fn(*args, **kwargs)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py\", line 314, in _step_py\n    self._time_step = self._env.step(packed)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py\", line 203, in step\n    self._current_time_step = self._step(action)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/batched_py_environment.py\", line 166, in _step\n    time_steps = self._envs[0].step(actions)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py\", line 203, in step\n    self._current_time_step = self._step(action)\n\n  File \"/home/andreas-z97x-ud3h/CM_Projects/CM_RL_Driver/RL/CM_py_env.py\", line 145, in _step\n    self._state, self.sim_time, self.s_road = Server(self.tcp_port).server_step(action)\n\n  File \"/home/andreas-z97x-ud3h/CM_Projects/CM_RL_Driver/RL/server.py\", line 43, in server_step\n    except:\n\nAttributeError: 'Server' object has no attribute 'old_msg_roh'\n\n\n\t [[{{node driver_loop/body/_1/driver_loop/step/step_py_func}}]] [Op:__inference_run_7385]\n\nFunction call stack:\nrun\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1e78b71a1ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mglobal_step_val\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     time_step, policy_state = collect_actor.run(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  AttributeError: 'Server' object has no attribute 'old_msg_roh'\nTraceback (most recent call last):\n\n  File \"/home/andreas-z97x-ud3h/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/home/andreas-z97x-ud3h/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py\", line 318, in _isolated_step_py\n    return self._execute(_step_py, *flattened_actions)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py\", line 214, in _execute\n    return fn(*args, **kwargs)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py\", line 314, in _step_py\n    self._time_step = self._env.step(packed)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py\", line 203, in step\n    self._current_time_step = self._step(action)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/batched_py_environment.py\", line 166, in _step\n    time_steps = self._envs[0].step(actions)\n\n  File \"/home/andreas-z97x-ud3h/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py\", line 203, in step\n    self._current_time_step = self._step(action)\n\n  File \"/home/andreas-z97x-ud3h/CM_Projects/CM_RL_Driver/RL/CM_py_env.py\", line 145, in _step\n    self._state, self.sim_time, self.s_road = Server(self.tcp_port).server_step(action)\n\n  File \"/home/andreas-z97x-ud3h/CM_Projects/CM_RL_Driver/RL/server.py\", line 43, in server_step\n    except:\n\nAttributeError: 'Server' object has no attribute 'old_msg_roh'\n\n\n\t [[{{node driver_loop/body/_1/driver_loop/step/step_py_func}}]] [Op:__inference_run_7385]\n\nFunction call stack:\nrun\n"
     ]
    }
   ],
   "source": [
    "while global_step_val < num_iterations:\n",
    "    start_time = time.time()\n",
    "    time_step, policy_state = collect_actor.run(\n",
    "        time_step=time_step,\n",
    "        policy_state=policy_state,\n",
    "    )\n",
    "    for _ in range(train_steps_per_iteration):\n",
    "        train_loss = train_step()\n",
    "    time_acc += time.time() - start_time\n",
    "\n",
    "    global_step_val = global_step.numpy()\n",
    "    if episode_val != train_metrics[0].result().numpy():\n",
    "        episode_val = train_metrics[0].result().numpy()\n",
    "        Server(14100).send_gui(\"DVAWrite RL_Agent.Episodes %d\" % episode_val)\n",
    "\n",
    "    if global_step_val % log_interval == 0:\n",
    "        logging.info('step = %d, loss = %f', global_step_val, train_loss.loss)\n",
    "        steps_per_sec = (global_step_val - timed_at_step) / time_acc\n",
    "        logging.info('%.3f steps/sec', steps_per_sec)\n",
    "        tf.compat.v2.summary.scalar(\n",
    "            name='global_steps_per_sec', data=steps_per_sec, step=global_step)\n",
    "        timed_at_step = global_step_val\n",
    "        time_acc = 0\n",
    "\n",
    "    for train_metric in train_metrics:\n",
    "        train_metric.tf_summaries(\n",
    "            train_step=global_step, step_metrics=train_metrics[:2])\n",
    "\n",
    "    if global_step_val % eval_interval == 0:\n",
    "        results = metric_utils.eager_compute(\n",
    "            eval_metrics,\n",
    "            tf_eval_env,\n",
    "            tf_eval_policy,\n",
    "            num_episodes=num_eval_episodes,\n",
    "            train_step=global_step,\n",
    "            summary_writer=eval_summary_writer,\n",
    "            summary_prefix='Metrics',\n",
    "        )\n",
    "    if eval_metrics_callback is not None:\n",
    "        eval_metrics_callback(results, global_step_val)\n",
    "    metric_utils.log_metrics(eval_metrics)\n",
    "\n",
    "    if global_step_val % train_checkpoint_interval == 0:\n",
    "        train_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "    if global_step_val % policy_checkpoint_interval == 0:\n",
    "        policy_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "    if global_step_val % rb_checkpoint_interval == 0:\n",
    "        rb_checkpointer.save(global_step=global_step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric_utils.eager_compute(\n",
    "    eval_metrics,\n",
    "    tf_eval_env,\n",
    "    tf_eval_policy,\n",
    "    num_episodes=num_eval_episodes,\n",
    "    train_step=global_step,\n",
    "    summary_writer=eval_summary_writer,\n",
    "    summary_prefix='Metrics',\n",
    ")"
   ]
  }
 ]
}