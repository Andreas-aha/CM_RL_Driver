{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "#import reverb\n",
    "import tempfile\n",
    "\n",
    "import logzero\n",
    "from logzero import logger as logging\n",
    "\n",
    "from tf_agents.environments import py_environment, batched_py_environment, tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.sac import sac_agent\n",
    "from tf_agents.agents.sac import tanh_normal_projection_network\n",
    "from tf_agents.experimental.train import actor\n",
    "from tf_agents.experimental.train import learner\n",
    "from tf_agents.experimental.train import triggers\n",
    "from tf_agents.experimental.train.utils import spec_utils\n",
    "from tf_agents.experimental.train.utils import strategy_utils\n",
    "from tf_agents.experimental.train.utils import train_utils\n",
    "from tf_agents.metrics import py_metrics, tf_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import py_tf_eager_policy, py_tf_policy\n",
    "from tf_agents.policies import random_py_policy, random_tf_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.eval import metric_utils\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "from tf_agents.drivers import dynamic_step_driver, dynamic_episode_driver\n",
    "\n",
    "\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from CM_py_env import CarMakerEnv\n",
    "from server import Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#root_dir = \"%s/rl_data/run%s\" % (os.getcwd(),  timestr)\n",
    "#os.mkdir(root_dir)\n",
    "root_dir = \"/home/andreas-z97x-ud3h/CM_Projects/CM_RL_Driver/RL/rl_data/run20201214-194710\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter\n",
    "num_iterations = 4000000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 10000 # @param {type:\"integer\"}\n",
    "train_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 100000 # @param {type:\"integer\"}\n",
    "collect_actor_num_steps = 2\n",
    "collect_actor_num_episodes = None # steps or episodes must be none\n",
    "\n",
    "batch_size = 512 # @param {type:\"integer\"}\n",
    "\n",
    "critic_learning_rate = 4e-4 # @param {typ\"}ber\"}\n",
    "actor_learning_rate = 8e-4 # @param {type\"}er\"}\n",
    "alpha_learning_rate = 4e-4 # @param {type\"}er\"}\n",
    "target_update_tau = 0.005 # @param {type:\"number\"}\n",
    "target_update_period = 1 # @param {type:\"number\"}\n",
    "gamma = 0.99 # @param {type:\"number\"}\n",
    "reward_scale_factor = 15.0 # @param {type:\"number\"}\n",
    "\n",
    "actor_fc_layer_params = (256, 256)\n",
    "critic_joint_fc_layer_params = (256, 256)\n",
    "\n",
    "log_interval = 100 # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 3 # @param {type:\"integer\"}\n",
    "eval_interval = 10000000000000000000 # @param {type:\"integer\"}\n",
    "\n",
    "policy_save_interval = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "summary_interval=1000\n",
    "summaries_flush_secs=10\n",
    "\n",
    "eval_metrics_callback=None\n",
    "\n",
    "train_checkpoint_interval=50000\n",
    "policy_checkpoint_interval=50000\n",
    "rb_checkpoint_interval=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logzero.logfile(\"%s/rotating-logfile.log\" % root_dir, maxBytes=1e6, backupCount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(root_dir, 'train')\n",
    "eval_dir = os.path.join(root_dir, 'eval')\n",
    "\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    train_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    eval_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "eval_metrics = [\n",
    "    tf_metrics.AverageReturnMetric(buffer_size=num_eval_episodes),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(buffer_size=num_eval_episodes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One Environment for collecting data during eval, and one for eval\n",
    "#Collect langsamer\n",
    "\n",
    "collect_env = CarMakerEnv(RTFac=999999, mode='collect', gamma=gamma, server=0)\n",
    "#collect_env2 = CarMakerEnv(RTFac=2, mode='collect', gamma=gamma, server=1)\n",
    "#collect_env3 = CarMakerEnv(RTFac=1, mode='collect', gamma=gamma, server=2)\n",
    "#collect_env4 = CarMakerEnv(RTFac=1, mode='collect', gamma=gamma, server=3)\n",
    "\n",
    "#collect_env = batched_py_environment.BatchedPyEnvironment( [collect_env1, collect_env2] )\n",
    "#eval_env = CarMakerEnv(RTFac=999999, mode='evaluate', gamma=gamma, server=1)\n",
    "\n",
    "#eval_env = collect_env\n",
    "\n",
    "tf_collect_env = tf_py_environment.TFPyEnvironment(collect_env)\n",
    "tf_eval_env = tf_collect_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Observation Spec:\nTensorSpec(shape=(18,), dtype=tf.float32, name='observation')\nAction Spec:\nBoundedTensorSpec(shape=(2,), dtype=tf.float32, name='action', minimum=array([-1.  , -3.14], dtype=float32), maximum=array([1.  , 3.14], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Check specs\n",
    "\n",
    "print('Observation Spec:')\n",
    "print(tf_collect_env.time_step_spec().observation)\n",
    "print('Action Spec:')\n",
    "print(tf_collect_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "# All variables and Agents need to be created under strategy.scope(), as you'll see below.\n",
    "\n",
    "# Critic for estimate of action values\n",
    "# Input is observation and an action\n",
    "# Output is estimate of action value (to see how good it would be)\n",
    "\n",
    "observation_spec, action_spec, time_step_spec = (\n",
    "      spec_utils.get_tensor_specs(tf_collect_env))\n",
    "\n",
    "\n",
    "critic_net = critic_network.CriticNetwork(\n",
    "      (observation_spec, action_spec),\n",
    "      observation_fc_layer_params=None,\n",
    "      action_fc_layer_params=None,\n",
    "      joint_fc_layer_params=critic_joint_fc_layer_params,\n",
    "      kernel_initializer='glorot_uniform',\n",
    "      last_kernel_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor network predicts parameters for a tanh-squashed MultivariateNormalDiag distribution.\n",
    "# Will be sampled conditioned on the current state (observation), if generation of action is needed.\n",
    "\n",
    "\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    observation_spec,\n",
    "    action_spec,\n",
    "    fc_layer_params=actor_fc_layer_params,\n",
    "    continuous_projection_net=(\n",
    "        tanh_normal_projection_network.TanhNormalProjectionNetwork))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init agent\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "tf_agent = sac_agent.SacAgent(\n",
    "    time_step_spec,\n",
    "    action_spec,\n",
    "    actor_network=actor_net,\n",
    "    critic_network=critic_net,\n",
    "    actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=actor_learning_rate),\n",
    "    critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=critic_learning_rate),\n",
    "    alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=alpha_learning_rate),\n",
    "    target_update_tau=target_update_tau,\n",
    "    target_update_period=target_update_period,\n",
    "    td_errors_loss_fn=tf.math.squared_difference,\n",
    "    gamma=gamma,\n",
    "    reward_scale_factor=reward_scale_factor,\n",
    "    train_step_counter=global_step)\n",
    "\n",
    "tf_agent.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/andreas-z97x-ud3h/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "WARNING:tensorflow:From /home/andreas-z97x-ud3h/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    tf_agent.collect_data_spec,\n",
    "    batch_size=1,\n",
    "    max_length=replay_buffer_capacity)\n",
    "# 6 instead of 2 for TD(5)\n",
    "\n",
    "def _filter_invalid_transition(trajectories, unused_arg1):\n",
    "      return ~trajectories.is_boundary()[0]\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=batch_size, num_steps=2, num_parallel_calls=2).unbatch().filter(\n",
    "            _filter_invalid_transition).batch(batch_size).prefetch(100)\n",
    "\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Policies\n",
    "# Agent has 2 policies\n",
    "\n",
    "# agent.policy — The main policy that is used for evaluation and deployment.\n",
    "# agent.collect_policy — A second policy that is used for data collection.\n",
    "\n",
    "tf_eval_policy = greedy_policy.GreedyPolicy(tf_agent.policy)\n",
    "\n",
    "tf_collect_policy = tf_agent.collect_policy\n",
    "\n",
    "# Additional random policy for initial collector\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(\n",
    "  tf_collect_env.time_step_spec(), tf_collect_env.action_spec())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(\n",
    "        buffer_size=num_eval_episodes, batch_size=tf_collect_env.batch_size),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(\n",
    "        buffer_size=num_eval_episodes, batch_size=tf_collect_env.batch_size),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa9a8252c70>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=train_dir,\n",
    "    agent=tf_agent,\n",
    "    global_step=global_step,\n",
    "    metrics=metric_utils.MetricsGroup(train_metrics, 'train_metrics'))\n",
    "policy_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(train_dir, 'policy'),\n",
    "    policy=tf_eval_policy,\n",
    "    global_step=global_step)\n",
    "rb_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(train_dir, 'replay_buffer'),\n",
    "    max_to_keep=1,\n",
    "    replay_buffer=replay_buffer)\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "rb_checkpointer.initialize_or_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor with the random policy and collect experiences to seed the replay buffer with\n",
    "\n",
    "initial_collect_actor = dynamic_step_driver.DynamicStepDriver(\n",
    "  tf_eval_env,\n",
    "  random_policy,\n",
    "  num_steps=initial_collect_steps,\n",
    "  observers=replay_observer+train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an Actor with the collect policy to gather more experiences during training\n",
    "\n",
    "# Steps per run nun 5 statt 1, weil smoother?\n",
    "\n",
    "\n",
    "if collect_actor_num_episodes is not None and collect_actor_num_steps is not None:\n",
    "  raise ValueError(\"Define num episodes OR num steps. One of them must be None.\")\n",
    "elif collect_actor_num_episodes is None:\n",
    "  collect_actor = dynamic_step_driver.DynamicStepDriver(\n",
    "    tf_collect_env,\n",
    "    tf_collect_policy,\n",
    "    num_steps=collect_actor_num_steps,\n",
    "    observers=replay_observer+train_metrics)\n",
    "elif collect_actor_num_steps is None:\n",
    "  collect_actor = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    tf_collect_env,\n",
    "    tf_collect_policy,\n",
    "    num_episodes=collect_actor_num_episodes,\n",
    "    observers=replay_observer+train_metrics)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_actor.run = common.function(initial_collect_actor.run)\n",
    "collect_actor.run = common.function(collect_actor.run)\n",
    "tf_agent.train = common.function(tf_agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = None\n",
    "policy_state = tf_collect_policy.get_initial_state(tf_collect_env.batch_size)\n",
    "timed_at_step = global_step.numpy()\n",
    "time_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if replay_buffer.num_frames() == 0:\n",
    "    # Collect initial replay data.\n",
    "    print(\n",
    "        'Initializing replay buffer by collecting experience for %d steps '\n",
    "        'with a random policy.' % initial_collect_steps)\n",
    "    initial_collect_actor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    experience, _ = next(iterator)\n",
    "    return tf_agent.train(experience)\n",
    "\n",
    "train_step = common.function(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step_val = global_step.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">:14] step = 788700, loss = 2223141.500000\n",
      "[I 201215 16:29:59 <ipython-input-22-74b9e68b8828>:16] 12.723 steps/sec\n",
      "[I 201215 16:30:07 <ipython-input-22-74b9e68b8828>:14] step = 788800, loss = 323500.875000\n",
      "[I 201215 16:30:07 <ipython-input-22-74b9e68b8828>:16] 12.744 steps/sec\n",
      "[I 201215 16:30:16 <ipython-input-22-74b9e68b8828>:14] step = 788900, loss = 648705.062500\n",
      "[I 201215 16:30:16 <ipython-input-22-74b9e68b8828>:16] 12.276 steps/sec\n",
      "[I 201215 16:30:24 <ipython-input-22-74b9e68b8828>:14] step = 789000, loss = 144307.968750\n",
      "[I 201215 16:30:24 <ipython-input-22-74b9e68b8828>:16] 12.747 steps/sec\n",
      "[I 201215 16:30:33 <ipython-input-22-74b9e68b8828>:14] step = 789100, loss = 232409.375000\n",
      "[I 201215 16:30:33 <ipython-input-22-74b9e68b8828>:16] 12.735 steps/sec\n",
      "[I 201215 16:30:41 <ipython-input-22-74b9e68b8828>:14] step = 789200, loss = 194435.578125\n",
      "[I 201215 16:30:41 <ipython-input-22-74b9e68b8828>:16] 12.711 steps/sec\n",
      "[I 201215 16:30:50 <ipython-input-22-74b9e68b8828>:14] step = 789300, loss = 1330842.750000\n",
      "[I 201215 16:30:50 <ipython-input-22-74b9e68b8828>:16] 12.293 steps/sec\n",
      "[I 201215 16:30:58 <ipython-input-22-74b9e68b8828>:14] step = 789400, loss = 954773.500000\n",
      "[I 201215 16:30:58 <ipython-input-22-74b9e68b8828>:16] 12.750 steps/sec\n",
      "[I 201215 16:31:06 <ipython-input-22-74b9e68b8828>:14] step = 789500, loss = 222453.906250\n",
      "[I 201215 16:31:06 <ipython-input-22-74b9e68b8828>:16] 12.751 steps/sec\n",
      "[I 201215 16:31:15 <ipython-input-22-74b9e68b8828>:14] step = 789600, loss = 1687255.875000\n",
      "[I 201215 16:31:15 <ipython-input-22-74b9e68b8828>:16] 12.772 steps/sec\n",
      "[I 201215 16:31:24 <ipython-input-22-74b9e68b8828>:14] step = 789700, loss = 2379015.000000\n",
      "[I 201215 16:31:24 <ipython-input-22-74b9e68b8828>:16] 11.987 steps/sec\n",
      "[I 201215 16:31:32 <ipython-input-22-74b9e68b8828>:14] step = 789800, loss = 329854.687500\n",
      "[I 201215 16:31:32 <ipython-input-22-74b9e68b8828>:16] 12.795 steps/sec\n",
      "[I 201215 16:31:40 <ipython-input-22-74b9e68b8828>:14] step = 789900, loss = 458272.375000\n",
      "[I 201215 16:31:40 <ipython-input-22-74b9e68b8828>:16] 12.747 steps/sec\n",
      "[I 201215 16:31:49 <ipython-input-22-74b9e68b8828>:14] step = 790000, loss = 254585.062500\n",
      "[I 201215 16:31:49 <ipython-input-22-74b9e68b8828>:16] 12.741 steps/sec\n",
      "[I 201215 16:31:57 <ipython-input-22-74b9e68b8828>:14] step = 790100, loss = 1286348.875000\n",
      "[I 201215 16:31:57 <ipython-input-22-74b9e68b8828>:16] 12.307 steps/sec\n",
      "[I 201215 16:32:05 <ipython-input-22-74b9e68b8828>:14] step = 790200, loss = 168694.968750\n",
      "[I 201215 16:32:06 <ipython-input-22-74b9e68b8828>:16] 12.743 steps/sec\n",
      "[I 201215 16:32:14 <ipython-input-22-74b9e68b8828>:14] step = 790300, loss = 302088.125000\n",
      "[I 201215 16:32:14 <ipython-input-22-74b9e68b8828>:16] 12.756 steps/sec\n",
      "[I 201215 16:32:23 <ipython-input-22-74b9e68b8828>:14] step = 790400, loss = 151223.875000\n",
      "[I 201215 16:32:23 <ipython-input-22-74b9e68b8828>:16] 12.106 steps/sec\n",
      "[I 201215 16:32:31 <ipython-input-22-74b9e68b8828>:14] step = 790500, loss = 2750713.500000\n",
      "[I 201215 16:32:31 <ipython-input-22-74b9e68b8828>:16] 12.719 steps/sec\n",
      "[I 201215 16:32:39 <ipython-input-22-74b9e68b8828>:14] step = 790600, loss = 95640.671875\n",
      "[I 201215 16:32:39 <ipython-input-22-74b9e68b8828>:16] 12.707 steps/sec\n",
      "[I 201215 16:32:48 <ipython-input-22-74b9e68b8828>:14] step = 790700, loss = 285600.406250\n",
      "[I 201215 16:32:48 <ipython-input-22-74b9e68b8828>:16] 12.711 steps/sec\n",
      "[I 201215 16:32:57 <ipython-input-22-74b9e68b8828>:14] step = 790800, loss = 113307.539062\n",
      "[I 201215 16:32:57 <ipython-input-22-74b9e68b8828>:16] 11.107 steps/sec\n",
      "[I 201215 16:33:05 <ipython-input-22-74b9e68b8828>:14] step = 790900, loss = 273212.593750\n",
      "[I 201215 16:33:05 <ipython-input-22-74b9e68b8828>:16] 12.801 steps/sec\n",
      "[I 201215 16:33:14 <ipython-input-22-74b9e68b8828>:14] step = 791000, loss = 136529.453125\n",
      "[I 201215 16:33:14 <ipython-input-22-74b9e68b8828>:16] 12.767 steps/sec\n",
      "[I 201215 16:33:20 <ipython-input-22-74b9e68b8828>:14] step = 791100, loss = 1968550.750000\n",
      "[I 201215 16:33:20 <ipython-input-22-74b9e68b8828>:16] 17.334 steps/sec\n",
      "[I 201215 16:33:26 <ipython-input-22-74b9e68b8828>:14] step = 791200, loss = 3248286.000000\n",
      "[I 201215 16:33:26 <ipython-input-22-74b9e68b8828>:16] 16.551 steps/sec\n",
      "[I 201215 16:33:33 <ipython-input-22-74b9e68b8828>:14] step = 791300, loss = 1055500.625000\n",
      "[I 201215 16:33:33 <ipython-input-22-74b9e68b8828>:16] 17.282 steps/sec\n",
      "[I 201215 16:33:39 <ipython-input-22-74b9e68b8828>:14] step = 791400, loss = 2815502.000000\n",
      "[I 201215 16:33:39 <ipython-input-22-74b9e68b8828>:16] 17.280 steps/sec\n",
      "[I 201215 16:33:45 <ipython-input-22-74b9e68b8828>:14] step = 791500, loss = 552619.062500\n",
      "[I 201215 16:33:45 <ipython-input-22-74b9e68b8828>:16] 17.259 steps/sec\n",
      "[I 201215 16:33:52 <ipython-input-22-74b9e68b8828>:14] step = 791600, loss = 2008382.000000\n",
      "[I 201215 16:33:52 <ipython-input-22-74b9e68b8828>:16] 16.575 steps/sec\n",
      "[I 201215 16:33:58 <ipython-input-22-74b9e68b8828>:14] step = 791700, loss = 223168.125000\n",
      "[I 201215 16:33:58 <ipython-input-22-74b9e68b8828>:16] 17.344 steps/sec\n",
      "[I 201215 16:34:04 <ipython-input-22-74b9e68b8828>:14] step = 791800, loss = 505418.156250\n",
      "[I 201215 16:34:04 <ipython-input-22-74b9e68b8828>:16] 17.374 steps/sec\n",
      "[I 201215 16:34:11 <ipython-input-22-74b9e68b8828>:14] step = 791900, loss = 374579.281250\n",
      "[I 201215 16:34:11 <ipython-input-22-74b9e68b8828>:16] 17.297 steps/sec\n",
      "[I 201215 16:34:17 <ipython-input-22-74b9e68b8828>:14] step = 792000, loss = 303707.812500\n",
      "[I 201215 16:34:17 <ipython-input-22-74b9e68b8828>:16] 16.762 steps/sec\n",
      "[I 201215 16:34:23 <ipython-input-22-74b9e68b8828>:14] step = 792100, loss = 240853.437500\n",
      "[I 201215 16:34:23 <ipython-input-22-74b9e68b8828>:16] 17.320 steps/sec\n",
      "[I 201215 16:34:29 <ipython-input-22-74b9e68b8828>:14] step = 792200, loss = 1239401.625000\n",
      "[I 201215 16:34:29 <ipython-input-22-74b9e68b8828>:16] 17.335 steps/sec\n",
      "[I 201215 16:34:36 <ipython-input-22-74b9e68b8828>:14] step = 792300, loss = 1392064.375000\n",
      "[I 201215 16:34:36 <ipython-input-22-74b9e68b8828>:16] 16.674 steps/sec\n",
      "[I 201215 16:34:43 <ipython-input-22-74b9e68b8828>:14] step = 792400, loss = 326461.093750\n",
      "[I 201215 16:34:43 <ipython-input-22-74b9e68b8828>:16] 16.183 steps/sec\n",
      "[I 201215 16:34:49 <ipython-input-22-74b9e68b8828>:14] step = 792500, loss = 551839.312500\n",
      "[I 201215 16:34:49 <ipython-input-22-74b9e68b8828>:16] 17.384 steps/sec\n",
      "[I 201215 16:34:55 <ipython-input-22-74b9e68b8828>:14] step = 792600, loss = 85116.281250\n",
      "[I 201215 16:34:55 <ipython-input-22-74b9e68b8828>:16] 17.357 steps/sec\n",
      "[I 201215 16:35:09 <ipython-input-22-74b9e68b8828>:14] step = 792700, loss = 1605441.250000\n",
      "[I 201215 16:35:09 <ipython-input-22-74b9e68b8828>:16] 7.545 steps/sec\n",
      "[I 201215 16:35:17 <ipython-input-22-74b9e68b8828>:14] step = 792800, loss = 2688310.750000\n",
      "[I 201215 16:35:17 <ipython-input-22-74b9e68b8828>:16] 12.293 steps/sec\n",
      "[I 201215 16:35:26 <ipython-input-22-74b9e68b8828>:14] step = 792900, loss = 650582.625000\n",
      "[I 201215 16:35:26 <ipython-input-22-74b9e68b8828>:16] 12.688 steps/sec\n",
      "[I 201215 16:35:34 <ipython-input-22-74b9e68b8828>:14] step = 793000, loss = 1567347.875000\n",
      "[I 201215 16:35:34 <ipython-input-22-74b9e68b8828>:16] 12.703 steps/sec\n",
      "[I 201215 16:35:42 <ipython-input-22-74b9e68b8828>:14] step = 793100, loss = 157399.390625\n",
      "[I 201215 16:35:42 <ipython-input-22-74b9e68b8828>:16] 12.733 steps/sec\n",
      "[I 201215 16:35:51 <ipython-input-22-74b9e68b8828>:14] step = 793200, loss = 3437715.750000\n",
      "[I 201215 16:35:51 <ipython-input-22-74b9e68b8828>:16] 12.293 steps/sec\n",
      "[I 201215 16:35:59 <ipython-input-22-74b9e68b8828>:14] step = 793300, loss = 466155.187500\n",
      "[I 201215 16:35:59 <ipython-input-22-74b9e68b8828>:16] 12.716 steps/sec\n",
      "[I 201215 16:36:06 <ipython-input-22-74b9e68b8828>:14] step = 793400, loss = 2594097.500000\n",
      "[I 201215 16:36:06 <ipython-input-22-74b9e68b8828>:16] 17.042 steps/sec\n",
      "[I 201215 16:36:12 <ipython-input-22-74b9e68b8828>:14] step = 793500, loss = 164405.937500\n",
      "[I 201215 16:36:12 <ipython-input-22-74b9e68b8828>:16] 16.113 steps/sec\n",
      "[I 201215 16:36:19 <ipython-input-22-74b9e68b8828>:14] step = 793600, loss = 1960204.000000\n",
      "[I 201215 16:36:19 <ipython-input-22-74b9e68b8828>:16] 17.287 steps/sec\n",
      "[I 201215 16:36:25 <ipython-input-22-74b9e68b8828>:14] step = 793700, loss = 1426657.250000\n",
      "[I 201215 16:36:25 <ipython-input-22-74b9e68b8828>:16] 17.283 steps/sec\n",
      "[I 201215 16:36:31 <ipython-input-22-74b9e68b8828>:14] step = 793800, loss = 126968.125000\n",
      "[I 201215 16:36:31 <ipython-input-22-74b9e68b8828>:16] 17.430 steps/sec\n",
      "[I 201215 16:36:42 <ipython-input-22-74b9e68b8828>:14] step = 793900, loss = 409999.062500\n",
      "[I 201215 16:36:42 <ipython-input-22-74b9e68b8828>:16] 9.901 steps/sec\n",
      "[I 201215 16:36:48 <ipython-input-22-74b9e68b8828>:14] step = 794000, loss = 8060675.000000\n",
      "[I 201215 16:36:48 <ipython-input-22-74b9e68b8828>:16] 17.287 steps/sec\n",
      "[I 201215 16:36:54 <ipython-input-22-74b9e68b8828>:14] step = 794100, loss = 211431.187500\n",
      "[I 201215 16:36:54 <ipython-input-22-74b9e68b8828>:16] 17.324 steps/sec\n",
      "[I 201215 16:37:11 <ipython-input-22-74b9e68b8828>:14] step = 794200, loss = 5558286.000000\n",
      "[I 201215 16:37:11 <ipython-input-22-74b9e68b8828>:16] 6.293 steps/sec\n",
      "[I 201215 16:37:24 <ipython-input-22-74b9e68b8828>:14] step = 794300, loss = 736644.500000\n",
      "[I 201215 16:37:24 <ipython-input-22-74b9e68b8828>:16] 7.531 steps/sec\n",
      "[I 201215 16:37:33 <ipython-input-22-74b9e68b8828>:14] step = 794400, loss = 303901.968750\n",
      "[I 201215 16:37:33 <ipython-input-22-74b9e68b8828>:16] 12.440 steps/sec\n",
      "[I 201215 16:37:41 <ipython-input-22-74b9e68b8828>:14] step = 794500, loss = 137683.781250\n",
      "[I 201215 16:37:41 <ipython-input-22-74b9e68b8828>:16] 12.734 steps/sec\n",
      "[I 201215 16:37:50 <ipython-input-22-74b9e68b8828>:14] step = 794600, loss = 91286.148438\n",
      "[I 201215 16:37:50 <ipython-input-22-74b9e68b8828>:16] 12.729 steps/sec\n",
      "[I 201215 16:37:58 <ipython-input-22-74b9e68b8828>:14] step = 794700, loss = 314447.031250\n",
      "[I 201215 16:37:58 <ipython-input-22-74b9e68b8828>:16] 12.750 steps/sec\n",
      "[I 201215 16:38:09 <ipython-input-22-74b9e68b8828>:14] step = 794800, loss = 1499868.250000\n",
      "[I 201215 16:38:09 <ipython-input-22-74b9e68b8828>:16] 9.370 steps/sec\n",
      "[I 201215 16:38:18 <ipython-input-22-74b9e68b8828>:14] step = 794900, loss = 2783691.000000\n",
      "[I 201215 16:38:18 <ipython-input-22-74b9e68b8828>:16] 12.424 steps/sec\n",
      "[I 201215 16:38:26 <ipython-input-22-74b9e68b8828>:14] step = 795000, loss = 1754866.500000\n",
      "[I 201215 16:38:26 <ipython-input-22-74b9e68b8828>:16] 12.698 steps/sec\n",
      "[I 201215 16:38:34 <ipython-input-22-74b9e68b8828>:14] step = 795100, loss = 335391.093750\n",
      "[I 201215 16:38:34 <ipython-input-22-74b9e68b8828>:16] 12.753 steps/sec\n",
      "[I 201215 16:38:43 <ipython-input-22-74b9e68b8828>:14] step = 795200, loss = 273953.750000\n",
      "[I 201215 16:38:43 <ipython-input-22-74b9e68b8828>:16] 12.678 steps/sec\n",
      "[I 201215 16:38:51 <ipython-input-22-74b9e68b8828>:14] step = 795300, loss = 2413822.500000\n",
      "[I 201215 16:38:51 <ipython-input-22-74b9e68b8828>:16] 12.473 steps/sec\n",
      "[I 201215 16:38:59 <ipython-input-22-74b9e68b8828>:14] step = 795400, loss = 441940.406250\n",
      "[I 201215 16:38:59 <ipython-input-22-74b9e68b8828>:16] 12.709 steps/sec\n",
      "[I 201215 16:39:08 <ipython-input-22-74b9e68b8828>:14] step = 795500, loss = 98993.445312\n",
      "[I 201215 16:39:08 <ipython-input-22-74b9e68b8828>:16] 12.697 steps/sec\n",
      "[I 201215 16:39:16 <ipython-input-22-74b9e68b8828>:14] step = 795600, loss = 5038484.000000\n",
      "[I 201215 16:39:16 <ipython-input-22-74b9e68b8828>:16] 12.701 steps/sec\n",
      "[I 201215 16:39:25 <ipython-input-22-74b9e68b8828>:14] step = 795700, loss = 388335.031250\n",
      "[I 201215 16:39:25 <ipython-input-22-74b9e68b8828>:16] 12.277 steps/sec\n",
      "[I 201215 16:39:33 <ipython-input-22-74b9e68b8828>:14] step = 795800, loss = 2617507.000000\n",
      "[I 201215 16:39:33 <ipython-input-22-74b9e68b8828>:16] 12.732 steps/sec\n",
      "[I 201215 16:39:42 <ipython-input-22-74b9e68b8828>:14] step = 795900, loss = 5017726.000000\n",
      "[I 201215 16:39:42 <ipython-input-22-74b9e68b8828>:16] 12.341 steps/sec\n",
      "[I 201215 16:39:50 <ipython-input-22-74b9e68b8828>:14] step = 796000, loss = 1732964.375000\n",
      "[I 201215 16:39:50 <ipython-input-22-74b9e68b8828>:16] 12.740 steps/sec\n",
      "[I 201215 16:39:58 <ipython-input-22-74b9e68b8828>:14] step = 796100, loss = 1785364.750000\n",
      "[I 201215 16:39:58 <ipython-input-22-74b9e68b8828>:16] 12.690 steps/sec\n",
      "[I 201215 16:40:07 <ipython-input-22-74b9e68b8828>:14] step = 796200, loss = 352365.156250\n",
      "[I 201215 16:40:07 <ipython-input-22-74b9e68b8828>:16] 12.738 steps/sec\n",
      "[I 201215 16:40:21 <ipython-input-22-74b9e68b8828>:14] step = 796300, loss = 1076964.000000\n",
      "[I 201215 16:40:21 <ipython-input-22-74b9e68b8828>:16] 7.368 steps/sec\n",
      "[I 201215 16:40:37 <ipython-input-22-74b9e68b8828>:14] step = 796400, loss = 1170068.375000\n",
      "[I 201215 16:40:37 <ipython-input-22-74b9e68b8828>:16] 6.170 steps/sec\n",
      "[I 201215 16:40:54 <ipython-input-22-74b9e68b8828>:14] step = 796500, loss = 3605403.250000\n",
      "[I 201215 16:40:54 <ipython-input-22-74b9e68b8828>:16] 6.183 steps/sec\n",
      "[I 201215 16:41:10 <ipython-input-22-74b9e68b8828>:14] step = 796600, loss = 211700.234375\n",
      "[I 201215 16:41:10 <ipython-input-22-74b9e68b8828>:16] 6.284 steps/sec\n",
      "[I 201215 16:41:27 <ipython-input-22-74b9e68b8828>:14] step = 796700, loss = 414228.843750\n",
      "[I 201215 16:41:27 <ipython-input-22-74b9e68b8828>:16] 6.012 steps/sec\n",
      "[I 201215 16:41:42 <ipython-input-22-74b9e68b8828>:14] step = 796800, loss = 2935148.250000\n",
      "[I 201215 16:41:42 <ipython-input-22-74b9e68b8828>:16] 7.332 steps/sec\n",
      "[I 201215 16:41:54 <ipython-input-22-74b9e68b8828>:14] step = 796900, loss = 2688203.500000\n",
      "[I 201215 16:41:54 <ipython-input-22-74b9e68b8828>:16] 8.311 steps/sec\n",
      "[I 201215 16:42:07 <ipython-input-22-74b9e68b8828>:14] step = 797000, loss = 2245326.500000\n",
      "[I 201215 16:42:07 <ipython-input-22-74b9e68b8828>:16] 8.303 steps/sec\n",
      "[I 201215 16:42:19 <ipython-input-22-74b9e68b8828>:14] step = 797100, loss = 1753073.875000\n",
      "[I 201215 16:42:19 <ipython-input-22-74b9e68b8828>:16] 8.087 steps/sec\n",
      "[I 201215 16:42:32 <ipython-input-22-74b9e68b8828>:14] step = 797200, loss = 2746347.000000\n",
      "[I 201215 16:42:32 <ipython-input-22-74b9e68b8828>:16] 8.335 steps/sec\n",
      "[I 201215 16:42:44 <ipython-input-22-74b9e68b8828>:14] step = 797300, loss = 554305.687500\n",
      "[I 201215 16:42:44 <ipython-input-22-74b9e68b8828>:16] 8.333 steps/sec\n",
      "[I 201215 16:42:57 <ipython-input-22-74b9e68b8828>:14] step = 797400, loss = 4317644.000000\n",
      "[I 201215 16:42:57 <ipython-input-22-74b9e68b8828>:16] 8.169 steps/sec\n",
      "[I 201215 16:43:10 <ipython-input-22-74b9e68b8828>:14] step = 797500, loss = 317614.500000\n",
      "[I 201215 16:43:10 <ipython-input-22-74b9e68b8828>:16] 8.324 steps/sec\n",
      "[I 201215 16:43:22 <ipython-input-22-74b9e68b8828>:14] step = 797600, loss = 3096196.500000\n",
      "[I 201215 16:43:22 <ipython-input-22-74b9e68b8828>:16] 8.315 steps/sec\n",
      "[I 201215 16:43:35 <ipython-input-22-74b9e68b8828>:14] step = 797700, loss = 285009.406250\n",
      "[I 201215 16:43:35 <ipython-input-22-74b9e68b8828>:16] 8.316 steps/sec\n",
      "[I 201215 16:43:47 <ipython-input-22-74b9e68b8828>:14] step = 797800, loss = 1592464.500000\n",
      "[I 201215 16:43:47 <ipython-input-22-74b9e68b8828>:16] 8.115 steps/sec\n",
      "[I 201215 16:44:00 <ipython-input-22-74b9e68b8828>:14] step = 797900, loss = 183354.437500\n",
      "[I 201215 16:44:00 <ipython-input-22-74b9e68b8828>:16] 8.338 steps/sec\n",
      "[I 201215 16:44:12 <ipython-input-22-74b9e68b8828>:14] step = 798000, loss = 446256.312500\n",
      "[I 201215 16:44:12 <ipython-input-22-74b9e68b8828>:16] 8.337 steps/sec\n",
      "[I 201215 16:44:25 <ipython-input-22-74b9e68b8828>:14] step = 798100, loss = 396602.468750\n",
      "[I 201215 16:44:25 <ipython-input-22-74b9e68b8828>:16] 8.322 steps/sec\n",
      "[I 201215 16:44:38 <ipython-input-22-74b9e68b8828>:14] step = 798200, loss = 2150195.000000\n",
      "[I 201215 16:44:38 <ipython-input-22-74b9e68b8828>:16] 8.092 steps/sec\n",
      "[I 201215 16:44:50 <ipython-input-22-74b9e68b8828>:14] step = 798300, loss = 1376497.875000\n",
      "[I 201215 16:44:50 <ipython-input-22-74b9e68b8828>:16] 8.333 steps/sec\n",
      "[I 201215 16:45:03 <ipython-input-22-74b9e68b8828>:14] step = 798400, loss = 1195890.750000\n",
      "[I 201215 16:45:03 <ipython-input-22-74b9e68b8828>:16] 8.337 steps/sec\n",
      "[I 201215 16:45:15 <ipython-input-22-74b9e68b8828>:14] step = 798500, loss = 1392656.750000\n",
      "[I 201215 16:45:15 <ipython-input-22-74b9e68b8828>:16] 8.337 steps/sec\n",
      "[I 201215 16:45:28 <ipython-input-22-74b9e68b8828>:14] step = 798600, loss = 307518.875000\n",
      "[I 201215 16:45:28 <ipython-input-22-74b9e68b8828>:16] 8.149 steps/sec\n",
      "[I 201215 16:45:41 <ipython-input-22-74b9e68b8828>:14] step = 798700, loss = 478711.906250\n",
      "[I 201215 16:45:41 <ipython-input-22-74b9e68b8828>:16] 8.346 steps/sec\n",
      "[I 201215 16:45:53 <ipython-input-22-74b9e68b8828>:14] step = 798800, loss = 249380.078125\n",
      "[I 201215 16:45:53 <ipython-input-22-74b9e68b8828>:16] 8.360 steps/sec\n",
      "[I 201215 16:46:06 <ipython-input-22-74b9e68b8828>:14] step = 798900, loss = 181923.046875\n",
      "[I 201215 16:46:06 <ipython-input-22-74b9e68b8828>:16] 8.348 steps/sec\n",
      "[I 201215 16:46:18 <ipython-input-22-74b9e68b8828>:14] step = 799000, loss = 4828365.000000\n",
      "[I 201215 16:46:18 <ipython-input-22-74b9e68b8828>:16] 8.101 steps/sec\n",
      "[I 201215 16:46:31 <ipython-input-22-74b9e68b8828>:14] step = 799100, loss = 256864.765625\n",
      "[I 201215 16:46:31 <ipython-input-22-74b9e68b8828>:16] 8.334 steps/sec\n",
      "[I 201215 16:46:43 <ipython-input-22-74b9e68b8828>:14] step = 799200, loss = 301776.031250\n",
      "[I 201215 16:46:43 <ipython-input-22-74b9e68b8828>:16] 8.328 steps/sec\n",
      "[I 201215 16:46:56 <ipython-input-22-74b9e68b8828>:14] step = 799300, loss = 6133811.000000\n",
      "[I 201215 16:46:56 <ipython-input-22-74b9e68b8828>:16] 8.322 steps/sec\n",
      "[I 201215 16:47:09 <ipython-input-22-74b9e68b8828>:14] step = 799400, loss = 2948498.000000\n",
      "[I 201215 16:47:09 <ipython-input-22-74b9e68b8828>:16] 8.119 steps/sec\n",
      "[I 201215 16:47:21 <ipython-input-22-74b9e68b8828>:14] step = 799500, loss = 198040.359375\n",
      "[I 201215 16:47:21 <ipython-input-22-74b9e68b8828>:16] 8.346 steps/sec\n",
      "[I 201215 16:47:34 <ipython-input-22-74b9e68b8828>:14] step = 799600, loss = 1240082.250000\n",
      "[I 201215 16:47:34 <ipython-input-22-74b9e68b8828>:16] 8.205 steps/sec\n",
      "[I 201215 16:47:46 <ipython-input-22-74b9e68b8828>:14] step = 799700, loss = 5087943.500000\n",
      "[I 201215 16:47:46 <ipython-input-22-74b9e68b8828>:16] 8.353 steps/sec\n",
      "[I 201215 16:47:59 <ipython-input-22-74b9e68b8828>:14] step = 799800, loss = 2310303.000000\n",
      "[I 201215 16:47:59 <ipython-input-22-74b9e68b8828>:16] 8.324 steps/sec\n",
      "[I 201215 16:48:12 <ipython-input-22-74b9e68b8828>:14] step = 799900, loss = 4801670.500000\n",
      "[I 201215 16:48:12 <ipython-input-22-74b9e68b8828>:16] 8.310 steps/sec\n",
      "[I 201215 16:48:24 <ipython-input-22-74b9e68b8828>:14] step = 800000, loss = 2551528.000000\n",
      "[I 201215 16:48:24 <ipython-input-22-74b9e68b8828>:16] 8.037 steps/sec\n",
      "[I 201215 16:48:37 <ipython-input-22-74b9e68b8828>:14] step = 800100, loss = 5003110.000000\n",
      "[I 201215 16:48:37 <ipython-input-22-74b9e68b8828>:16] 8.281 steps/sec\n",
      "[I 201215 16:48:50 <ipython-input-22-74b9e68b8828>:14] step = 800200, loss = 306432.781250\n",
      "[I 201215 16:48:50 <ipython-input-22-74b9e68b8828>:16] 8.188 steps/sec\n",
      "[I 201215 16:49:02 <ipython-input-22-74b9e68b8828>:14] step = 800300, loss = 278945.062500\n",
      "[I 201215 16:49:02 <ipython-input-22-74b9e68b8828>:16] 8.317 steps/sec\n",
      "[I 201215 16:49:15 <ipython-input-22-74b9e68b8828>:14] step = 800400, loss = 300751.875000\n",
      "[I 201215 16:49:15 <ipython-input-22-74b9e68b8828>:16] 8.295 steps/sec\n",
      "[I 201215 16:49:27 <ipython-input-22-74b9e68b8828>:14] step = 800500, loss = 255478.921875\n",
      "[I 201215 16:49:27 <ipython-input-22-74b9e68b8828>:16] 8.160 steps/sec\n",
      "[I 201215 16:49:40 <ipython-input-22-74b9e68b8828>:14] step = 800600, loss = 2635945.500000\n",
      "[I 201215 16:49:40 <ipython-input-22-74b9e68b8828>:16] 8.298 steps/sec\n",
      "[I 201215 16:49:52 <ipython-input-22-74b9e68b8828>:14] step = 800700, loss = 335463.500000\n",
      "[I 201215 16:49:52 <ipython-input-22-74b9e68b8828>:16] 8.306 steps/sec\n",
      "[I 201215 16:50:05 <ipython-input-22-74b9e68b8828>:14] step = 800800, loss = 161368.843750\n",
      "[I 201215 16:50:05 <ipython-input-22-74b9e68b8828>:16] 8.305 steps/sec\n",
      "[I 201215 16:50:18 <ipython-input-22-74b9e68b8828>:14] step = 800900, loss = 111534.656250\n",
      "[I 201215 16:50:18 <ipython-input-22-74b9e68b8828>:16] 8.054 steps/sec\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-74b9e68b8828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mglobal_step_val\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     time_step, policy_state = collect_actor.run(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_agents/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while global_step_val < num_iterations:\n",
    "    start_time = time.time()\n",
    "    time_step, policy_state = collect_actor.run(\n",
    "        time_step=time_step,\n",
    "        policy_state=policy_state,\n",
    "    )\n",
    "    for _ in range(train_steps_per_iteration):\n",
    "        train_loss = train_step()\n",
    "    time_acc += time.time() - start_time\n",
    "\n",
    "    global_step_val = global_step.numpy()\n",
    "\n",
    "    if global_step_val % log_interval == 0:\n",
    "        logging.info('step = %d, loss = %f', global_step_val, train_loss.loss)\n",
    "        steps_per_sec = (global_step_val - timed_at_step) / time_acc\n",
    "        logging.info('%.3f steps/sec', steps_per_sec)\n",
    "        tf.compat.v2.summary.scalar(\n",
    "            name='global_steps_per_sec', data=steps_per_sec, step=global_step)\n",
    "        timed_at_step = global_step_val\n",
    "        time_acc = 0\n",
    "\n",
    "    for train_metric in train_metrics:\n",
    "        train_metric.tf_summaries(\n",
    "            train_step=global_step, step_metrics=train_metrics[:2])\n",
    "\n",
    "    if global_step_val % eval_interval == 0:\n",
    "        results = metric_utils.eager_compute(\n",
    "            eval_metrics,\n",
    "            tf_eval_env,\n",
    "            tf_eval_policy,\n",
    "            num_episodes=num_eval_episodes,\n",
    "            train_step=global_step,\n",
    "            summary_writer=eval_summary_writer,\n",
    "            summary_prefix='Metrics',\n",
    "        )\n",
    "    if eval_metrics_callback is not None:\n",
    "        eval_metrics_callback(results, global_step_val)\n",
    "    metric_utils.log_metrics(eval_metrics)\n",
    "\n",
    "    if global_step_val % train_checkpoint_interval == 0:\n",
    "        train_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "    if global_step_val % policy_checkpoint_interval == 0:\n",
    "        policy_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "    if global_step_val % rb_checkpoint_interval == 0:\n",
    "        rb_checkpointer.save(global_step=global_step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric_utils.eager_compute(\n",
    "    eval_metrics,\n",
    "    tf_eval_env,\n",
    "    tf_eval_policy,\n",
    "    num_episodes=num_eval_episodes,\n",
    "    train_step=global_step,\n",
    "    summary_writer=eval_summary_writer,\n",
    "    summary_prefix='Metrics',\n",
    ")"
   ]
  }
 ]
}